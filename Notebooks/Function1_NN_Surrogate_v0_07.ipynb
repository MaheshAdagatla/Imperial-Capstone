{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "#  Neural Network Surrogate for Black-Box Optimisation (BBO)\n",
        "# ============================================================\n",
        "#  Overview:\n",
        "#  This code trains a PyTorch neural network surrogate model to\n",
        "#  approximate a black-box function and identify the next best\n",
        "#  query point via Monte Carlo sampling.\n",
        "#\n",
        "#  Core idea:\n",
        "#  - The surrogate learns the relationship between inputs (X)\n",
        "#    and outputs (y).\n",
        "#  - Monte Carlo sampling generates many random candidates.\n",
        "#  - The surrogate predicts their outputs.\n",
        "#  - The best candidate (highest predicted y) is chosen as the\n",
        "#    next query point.\n",
        "#\n",
        "#  Monte Carlo approach:\n",
        "#  ---------------------\n",
        "#  Since black-box functions are unknown and costly to query,\n",
        "#  Monte Carlo sampling provides an efficient, probabilistic\n",
        "#  method to explore the input space and estimate promising\n",
        "#  regions for improvement.\n",
        "#\n",
        "#  Exploration vs. Exploitation Controls:\n",
        "#  --------------------------------------\n",
        "#  - Learning Rate (lr):\n",
        "#       Higher = faster, noisier updates (more exploration)\n",
        "#       Lower  = slower, stable convergence (more exploitation)\n",
        "#  - Batch Size (batch_size):\n",
        "#       Smaller = more stochastic gradient (exploration)\n",
        "#       Larger  = smoother gradient, focus on known good regions (exploitation)\n",
        "#  - Monte Carlo Samples (n_candidates):\n",
        "#       More = broader coverage of search space (exploration)\n",
        "#       Fewer = faster computation, focus on known regions (exploitation)\n",
        "#\n",
        "# ============================================================\n",
        "#\n",
        "# v0.02 - Full rewrite using Pytorch with clear functions for easier understanding.\n",
        "# v0.03 - Updated to use GP to explore and shortlist a region, then use NN for\n",
        "#         exploitation within the shortlisted region.\n",
        "# v0.04 - Updated to down-weight low importance dimensions\n",
        "# v0.05 - Exploitation started. Updated a new generate sample candidates function\n",
        "#         to generate importance weighted candidates in the exploitation region.\n",
        "#         Also updated gp_acq_k to exploit\n",
        "# v0.06 - Exploitation continuing with tighter hyperparameters:\n",
        "#         stage1_size = 12000\n",
        "#         stage2_size = 1000\n",
        "#         gp_acq_k    = 0.3\n",
        "#         nn_batch    = 512\n",
        "#         base_radius = 0.15\n",
        "# v0.07 - Exploitation continuing with tighter hyperparameters:\n",
        "#         stage1_size   = 10000\n",
        "#         stage2_size   = 800\n",
        "#         gp_acq_k      = 0.20\n",
        "#         nn_batch      = 512\n",
        "#         base_radius   = 0.12\n"
      ],
      "metadata": {
        "id": "-3rx1v8RLUdv"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iK57bCX8Pf1N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e303eb4d-0166-4b93-8bde-0f6b24e32a31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount drive for loading initial input and output files\n",
        "def mount_drive():\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "\n",
        "mount_drive()\n",
        "\n",
        "# Import Libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.gaussian_process.kernels import Matern, WhiteKernel, ConstantKernel as C\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the initial files\n",
        "def load_initial_files(function='1'):\n",
        "  path = 'drive/MyDrive/data/'\n",
        "  given_X = path + 'fn' + function + '_initial_inputs.npy'\n",
        "  given_y = path + 'fn' + function + '_initial_outputs.npy'\n",
        "  X = np.load(given_X)        # shape (n0, d)\n",
        "  y = np.load(given_y)       # shape (n0,)\n",
        "\n",
        "  return X, y\n",
        "\n",
        "# Append new data from recent queries\n",
        "def append_new_data(X, y, function):\n",
        "  if function == '1':\n",
        "    X = np.append(X,[[0.701438, 0.897524]], axis=0)  # Append week1 inputs\n",
        "    y = np.append(y, 4.907008577514035e-55)         # Append week1 outputs\n",
        "    X = np.append(X,[[0.608788, 0.208839]], axis=0)  # Append week2 inputs\n",
        "    y = np.append(y, -3.407789887257921e-57)         # Append week2 outputs\n",
        "    X = np.append(X,[[0.937387, 0.537998]], axis=0)  # Append week3 inputs\n",
        "    y = np.append(y, -1.8248983945966781e-72)         # Append week3 outputs\n",
        "    X = np.append(X,[[0.401144, 0.347316]], axis=0)  # Append week4 inputs\n",
        "    y = np.append(y, -0.000052943333535254514)         # Append week4 outputs\n",
        "    X = np.append(X,[[0.815411, 0.802906]], axis=0)  # Append week5 inputs\n",
        "    y = np.append(y, 2.3120136577868056e-46)         # Append week5 outputs\n",
        "    X = np.append(X,[[0.147927, 0.999351]], axis=0)  # Append week6 inputs\n",
        "    y = np.append(y, -1.0556884679861184e-256)         # Append week6 outputs\n",
        "    X = np.append(X,[[0.961902, 0.541510]], axis=0)  # Append week7 inputs\n",
        "    y = np.append(y, -4.446243588517271e-83)         # Append week7 outputs\n",
        "    X = np.append(X,[[0.354466, 0.463725]], axis=0)  # Append week8 inputs\n",
        "    y = np.append(y, 0.000004670359491308217)         # Append week8 outputs\n",
        "    X = np.append(X,[[0.200840, 0.740525]], axis=0)  # Append week9 inputs\n",
        "    y = np.append(y, -2.223577503605569e-105)         # Append week9 outputs\n",
        "    X = np.append(X,[[0.329036, 0.431477]], axis=0)  # Append week10 inputs\n",
        "    y = np.append(y, -7.726124369273896e-7)         # Append week10 outputs\n",
        "  elif function == '2':\n",
        "    X = np.append(X,[[0.695813, 0.000000]], axis=0)  # Append week inputs\n",
        "    y = np.append(y, 0.6257440183692108)         # Append week1 outputs\n",
        "    X = np.append(X,[[0.969061, 0.774664]], axis=0)  # Append week2 inputs\n",
        "    y = np.append(y, 0.033917749094575816)         # Append week2 outputs\n",
        "    X = np.append(X,[[0.690739, 0.962975]], axis=0)  # Append week3 inputs\n",
        "    y = np.append(y, 0.6440194651539941)         # Append week3 outputs\n",
        "    X = np.append(X,[[0.000000, 0.982469]], axis=0)  # Append week4 inputs\n",
        "    y = np.append(y, 0.011920662637457252)         # Append week4 outputs\n",
        "    X = np.append(X,[[0.819992, 0.888300]], axis=0)  # Append week5 inputs\n",
        "    y = np.append(y, -0.05572035846713359)         # Append week5 outputs\n",
        "    X = np.append(X,[[0.576225, 0.995582]], axis=0)  # Append week6 inputs\n",
        "    y = np.append(y, -0.05917879343392843)         # Append week6 outputs\n",
        "    X = np.append(X,[[0.686326, 0.048467]], axis=0)  # Append week7 inputs\n",
        "    y = np.append(y, 0.5502098056853213)         # Append week7 outputs\n",
        "    X = np.append(X,[[0.684793, 0.736977]], axis=0)  # Append week8 inputs\n",
        "    y = np.append(y, 0.6051181573714066)         # Append week8 outputs\n",
        "    X = np.append(X,[[0.697663, 0.999431]], axis=0)  # Append week9 inputs\n",
        "    y = np.append(y, 0.6074029564402459)         # Append week9 outputs\n",
        "    X = np.append(X,[[0.684762, 0.956283]], axis=0)  # Append week10 inputs\n",
        "    y = np.append(y, 0.5911243348817143)         # Append week10 outputs\n",
        "  elif function == '3':\n",
        "    X = np.append(X,[[0.000000, 0.000000, 0.000000]], axis=0)  # Append week1 inputs\n",
        "    y = np.append(y, -0.1755204613669372)         # Append week1 outputs\n",
        "    X = np.append(X,[[0.999999, 0.183024, 0.788109]], axis=0)  # Append week2 inputs\n",
        "    y = np.append(y, -0.10594389054163186)         # Append week2 outputs\n",
        "    X = np.append(X,[[0.937840, 0.999999, 0.405928]], axis=0)  # Append week3 inputs\n",
        "    y = np.append(y, -0.05889151139553504)         # Append week3 outputs\n",
        "    X = np.append(X,[[0.523777, 0.465195, 0.442681]], axis=0)  # Append week4 inputs\n",
        "    y = np.append(y, -0.005996811424753983)         # Append week4 outputs\n",
        "    X = np.append(X,[[0.503614, 0.496940, 0.415922]], axis=0)  # Append week5 inputs\n",
        "    y = np.append(y, -0.0062783618309617175)         # Append week5 outputs\n",
        "    X = np.append(X,[[0.306294, 0.000901, 0.737840]], axis=0)  # Append week6 inputs\n",
        "    y = np.append(y, -0.1868873865434488)         # Append week6 outputs\n",
        "    X = np.append(X,[[0.785819, 0.951069, 0.007398]], axis=0)  # Append week7 inputs\n",
        "    y = np.append(y, -0.12354269078229708)         # Append week7 outputs\n",
        "    X = np.append(X,[[0.671012, 0.540880, 0.410996]], axis=0)  # Append week8 inputs\n",
        "    y = np.append(y, -0.016078870026236092)         # Append week8 outputs\n",
        "    X = np.append(X,[[0.511600, 0.466301, 0.440801]], axis=0)  # Append week9 inputs\n",
        "    y = np.append(y, -0.003448118792089531)         # Append week9 outputs\n",
        "    X = np.append(X,[[0.541094, 0.476141, 0.429833]], axis=0)  # Append week10 inputs\n",
        "    y = np.append(y, -0.006776539824628652)         # Append week10 outputs\n",
        "  elif function == '4':\n",
        "    X = np.append(X,[[0.440415, 0.425453, 0.378353, 0.397106]], axis=0)  # Append week1 inputs\n",
        "    y = np.append(y, 0.2601025838576061)         # Append week1 outputs\n",
        "    X = np.append(X,[[0.410011, 0.415255, 0.344454, 0.438808]], axis=0)  # Append week2 inputs\n",
        "    y = np.append(y, 0.3983591561199096)         # Append week2 outputs\n",
        "    X = np.append(X,[[0.384038, 0.412994, 0.399499, 0.436890]], axis=0)  # Append week3 inputs\n",
        "    y = np.append(y, 0.2987152140170406)         # Append week3 outputs\n",
        "    X = np.append(X,[[0.391529, 0.451226, 0.356835, 0.420242]], axis=0)  # Append week4 inputs\n",
        "    y = np.append(y, 0.06384840143364956)         # Append week4 outputs\n",
        "    X = np.append(X,[[0.529644, 0.477474, 0.456444, 0.497979]], axis=0)  # Append week5 inputs\n",
        "    y = np.append(y, -3.620742573150156)         # Append week5 outputs\n",
        "    X = np.append(X,[[0.362616, 0.390935, 0.358916, 0.408803]], axis=0)  # Append week6 inputs\n",
        "    y = np.append(y, 0.5941496830193782)         # Append week6 outputs\n",
        "    X = np.append(X,[[0.408168, 0.424670, 0.350333, 0.464759]], axis=0)  # Append week7 inputs\n",
        "    y = np.append(y, -0.28307671964285275)         # Append week7 outputs\n",
        "    X = np.append(X,[[0.462778, 0.459808, 0.427924, 0.383695]], axis=0)  # Append week8 inputs\n",
        "    y = np.append(y, -1.072387515133428)         # Append week8 outputs\n",
        "    X = np.append(X,[[0.337602, 0.314128, 0.323601, 0.447251]], axis=0)  # Append week9 inputs\n",
        "    y = np.append(y, -0.9951880222627056)         # Append week9 outputs\n",
        "    X = np.append(X,[[0.379054, 0.415621, 0.376105, 0.405300]], axis=0)  # Append week10 inputs\n",
        "    y = np.append(y, 0.4527725055900622)         # Append week10 outputs\n",
        "  elif function == '5':\n",
        "    X = np.append(X,[[0.000000, 0.827185, 0.999999, 0.999999]], axis=0)  # Append week1 inputs\n",
        "    y = np.append(y, 2781.638812419282)         # Append week1 outputs\n",
        "    X = np.append(X,[[0.058940, 0.195873, 0.872581, 0.998561]], axis=0)  # Append week2 inputs\n",
        "    y = np.append(y, 848.8896402098709)         # Append week2 outputs\n",
        "    X = np.append(X,[[0.166206, 0.999999, 0.999999, 0.999999]], axis=0)  # Append week3 inputs\n",
        "    y = np.append(y, 4444.256290210307)         # Append week3 outputs\n",
        "    X = np.append(X,[[0.259704, 0.866240, 0.999999, 0.078304]], axis=0)  # Append week4 inputs\n",
        "    y = np.append(y, 837.6996715082641)         # Append week4 outputs\n",
        "    X = np.append(X,[[0.405221, 0.818629, 0.840579, 0.874304]], axis=0)  # Append week5 inputs\n",
        "    y = np.append(y, 848.6842411794586)         # Append week5 outputs\n",
        "    X = np.append(X,[[0.379668, 0.980190, 0.997527, 0.939278]], axis=0)  # Append week6 inputs\n",
        "    y = np.append(y, 3506.2636242750236)         # Append week6 outputs\n",
        "    X = np.append(X,[[0.165658, 0.993001, 0.985802, 0.828885]], axis=0)  # Append week7 inputs\n",
        "    y = np.append(y, 2570.8680824924277)         # Append week7 outputs\n",
        "    X = np.append(X,[[0.450158, 0.310399, 0.558612, 0.719998]], axis=0)  # Append week8 inputs\n",
        "    y = np.append(y, 1.9175678320859924)         # Append week8 outputs\n",
        "    X = np.append(X,[[0.106033, 0.999999, 0.999999, 0.999999]], axis=0)  # Append week9 inputs\n",
        "    y = np.append(y, 4441.287683454212)         # Append week9 outputs\n",
        "    X = np.append(X,[[0.161038, 0.999999, 0.999999, 0.999999]], axis=0)  # Append week10 inputs\n",
        "    y = np.append(y, 4443.855101752938)         # Append week10 outputs\n",
        "  elif function == '6':\n",
        "    X = np.append(X,[[0.464910, 0.242338, 0.574752, 0.999999, 0.000000]], axis=0)  # Append week1 inputs\n",
        "    y = np.append(y, -0.5265043497038704)         # Append week1 outputs\n",
        "    X = np.append(X,[[0.537065, 0.317653, 0.626041, 0.898937, 0.148218]], axis=0)  # Append week2 inputs\n",
        "    y = np.append(y, -0.41510731628352715)         # Append week2 outputs\n",
        "    X = np.append(X,[[0.455585, 0.174069, 0.999999, 0.999999, 0.292903]], axis=0)  # Append week3 inputs\n",
        "    y = np.append(y, -1.0104998624615082)         # Append week3 outputs\n",
        "    X = np.append(X,[[0.525055, 0.369255, 0.490228, 0.765387, 0.025091]], axis=0)  # Append week4 inputs\n",
        "    y = np.append(y, -0.3481623700173726)         # Append week4 outputs\n",
        "    X = np.append(X,[[0.541275, 0.517331, 0.640338, 0.739537, 0.379138]], axis=0)  # Append week5 inputs\n",
        "    y = np.append(y, -0.6094732138365111)         # Append week5 outputs\n",
        "    X = np.append(X,[[0.377302, 0.427069, 0.554688, 0.835249, 0.037887]], axis=0)  # Append week6 inputs\n",
        "    y = np.append(y, -0.3821980197564756)         # Append week6 outputs\n",
        "    X = np.append(X,[[0.399356, 0.472775, 0.272075, 0.930991, 0.004327]], axis=0)  # Append week7 inputs\n",
        "    y = np.append(y, -0.7153807487746384)         # Append week7 outputs\n",
        "    X = np.append(X,[[0.352618, 0.580837, 0.570192, 0.621771, 0.372965]], axis=0)  # Append week8 inputs\n",
        "    y = np.append(y, -0.7718310362808554)         # Append week8 outputs\n",
        "    X = np.append(X,[[0.463141, 0.457153, 0.632226, 0.697789, 0.000000]], axis=0)  # Append week9 inputs\n",
        "    y = np.append(y, -0.3593032465991644)         # Append week9 outputs\n",
        "    X = np.append(X,[[0.485318, 0.354410, 0.532001, 0.735756, 0.002593]], axis=0)  # Append week10 inputs\n",
        "    y = np.append(y, -0.2563938551700072)         # Append week10 outputs\n",
        "  elif function == '7':\n",
        "    X = np.append(X,[[0.000000, 0.247036, 0.408965, 0.217149, 0.377534, 0.746590]], axis=0)  # Append week1 inputs\n",
        "    y = np.append(y, 2.3034568430941222)         # Append week1 outputs\n",
        "    X = np.append(X,[[0.000000, 0.181841, 0.435826, 0.062982, 0.361647, 0.858489]], axis=0)  # Append week2 inputs\n",
        "    y = np.append(y, 1.3279380639726712)         # Append week2 outputs\n",
        "    X = np.append(X,[[0.000000, 0.166738, 0.211207, 0.080984, 0.381370, 0.746608]], axis=0)  # Append week3 inputs\n",
        "    y = np.append(y, 1.433484749556216)         # Append week3 outputs\n",
        "    X = np.append(X,[[0.000000, 0.198493, 0.750365, 0.247059, 0.370826, 0.980737]], axis=0)  # Append week4 inputs\n",
        "    y = np.append(y, 1.239424289285777)         # Append week4 outputs\n",
        "    X = np.append(X,[[0.456843, 0.374177, 0.452545, 0.525118, 0.456228, 0.722847]], axis=0)  # Append week5 inputs\n",
        "    y = np.append(y, 0.8787401362260749)         # Append week5 outputs\n",
        "    X = np.append(X,[[0.002100, 0.111359, 0.320991, 0.376242, 0.229457, 0.955090]], axis=0)  # Append week6 inputs\n",
        "    y = np.append(y, 1.1302577537063068)         # Append week6 outputs\n",
        "    X = np.append(X,[[0.051607, 0.242133, 0.329607, 0.131528, 0.404377, 0.688463]], axis=0)  # Append week7 inputs\n",
        "    y = np.append(y, 1.974692744635984)         # Append week7 outputs\n",
        "    X = np.append(X,[[0.391166, 0.399851, 0.480060, 0.389445, 0.406096, 0.616639]], axis=0)  # Append week8 inputs\n",
        "    y = np.append(y, 1.794628814733577)         # Append week8 outputs\n",
        "    X = np.append(X,[[0.000000, 0.273026, 0.493981, 0.248861, 0.418811, 0.645849]], axis=0)  # Append week9 inputs\n",
        "    y = np.append(y, 2.2957847800972426)         # Append week9 outputs\n",
        "    X = np.append(X,[[0.000000, 0.246499, 0.426534, 0.258151, 0.365936, 0.706056]], axis=0)  # Append week10 inputs\n",
        "    y = np.append(y, 2.550792309384511)         # Append week10 outputs\n",
        "  elif function == '8':\n",
        "    X = np.append(X,[[0.060275, 0.000000, 0.134973, 0.000000, 0.999999, 0.404343, 0.057755, 0.516689]], axis=0)  # Append week1 inputs\n",
        "    y = np.append(y, 9.8814582425914)         # Append week1 outputs\n",
        "    X = np.append(X,[[0.122654, 0.153991, 0.162413, 0.045600, 0.999999, 0.536650, 0.260832, 0.932950]], axis=0)  # Append week2 inputs\n",
        "    y = np.append(y, 9.9450768395815)         # Append week2 outputs\n",
        "    X = np.append(X,[[0.085442, 0.318585, 0.000000, 0.239064, 0.999999, 0.927570, 0.142651, 0.932950]], axis=0)  # Append week3 inputs\n",
        "    y = np.append(y, 9.6920435401985)         # Append week3 outputs\n",
        "    X = np.append(X,[[0.266427, 0.000000, 0.185600, 0.000000, 0.999999, 0.210401, 0.179882, 0.156373]], axis=0)  # Append week4 inputs\n",
        "    y = np.append(y, 9.7659726871796)         # Append week4 outputs\n",
        "    X = np.append(X,[[0.514029, 0.459555, 0.534367, 0.406509, 0.744510, 0.663310, 0.578111, 0.756422]], axis=0)  # Append week5 inputs\n",
        "    y = np.append(y, 8.6884084301446)         # Append week5 outputs\n",
        "    X = np.append(X,[[0.026980, 0.613170, 0.025877, 0.359845, 0.896836, 0.008212, 0.028519, 0.131032]], axis=0)  # Append week6 inputs\n",
        "    y = np.append(y, 9.3709013812716)         # Append week6 outputs\n",
        "    X = np.append(X,[[0.065492, 0.074877, 0.151838, 0.036631, 0.882332, 0.837480, 0.404222, 0.901998]], axis=0)  # Append week7 inputs\n",
        "    y = np.append(y, 9.7678761465696)         # Append week7 outputs\n",
        "    X = np.append(X,[[0.416048, 0.599220, 0.417048, 0.424239, 0.551884, 0.585992, 0.386618, 0.514817]], axis=0)  # Append week8 inputs\n",
        "    y = np.append(y, 9.1674784539701)         # Append week8 outputs\n",
        "    X = np.append(X,[[0.032703, 0.075576, 0.154423, 0.035445, 0.990590, 0.497687, 0.174691, 0.986528]], axis=0)  # Append week9 inputs\n",
        "    y = np.append(y, 9.9361018945346)         # Append week9 outputs\n",
        "    X = np.append(X,[[0.128787, 0.124725, 0.195336, 0.024228, 0.999999, 0.534909, 0.223820, 0.947785]], axis=0)  # Append week10 inputs\n",
        "    y = np.append(y, 9.934630153261)         # Append week10 outputs\n",
        "\n",
        "\n",
        "  return X, y\n",
        "\n",
        "# Normalise X and y\n",
        "def normalise_data(X, y):\n",
        "  x_scaler = StandardScaler()\n",
        "  Xn = x_scaler.fit_transform(X)\n",
        "  y_mean = y.mean()\n",
        "  y_std = y.std() if y.std() > 0 else 1.0\n",
        "  yn = (y - y_mean) / y_std   # Normalize target manually (avoid sklearn overhead)\n",
        "\n",
        "  return Xn, yn, y_mean, y_std, x_scaler"
      ],
      "metadata": {
        "id": "D78VjqxB7Zkf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Neural Network surrogate model\n",
        "class SurrogateNN(nn.Module):\n",
        "    def __init__(self, input_dim, dropout_rate=0.2):\n",
        "        super(SurrogateNN, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(32, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "# Train Surrogate NN model with optional mini batching\n",
        "def train_nn(X_train, y_train, input_dim, lr=0.01, epochs=300, batch_size=None):\n",
        "    \"\"\"\n",
        "    Trains the neural network surrogate.\n",
        "    If batch_size is None, uses full-batch training.\n",
        "    \"\"\"\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    nn_model = SurrogateNN(input_dim).to(device)\n",
        "    optimizer = optim.Adam(nn_model.parameters(), lr=lr)\n",
        "    loss_fn = nn.MSELoss()\n",
        "\n",
        "    X_t = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
        "    y_t = torch.tensor(y_train, dtype=torch.float32).view(-1, 1).to(device)\n",
        "\n",
        "    if batch_size is not None:\n",
        "        dataset = TensorDataset(X_t, y_t)\n",
        "        loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "    else:\n",
        "        loader = [(X_t, y_t)]  # full-batch fallback\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        for xb, yb in loader:\n",
        "            optimizer.zero_grad()\n",
        "            preds = nn_model(xb)\n",
        "            loss = loss_fn(preds, yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    return nn_model\n",
        "\n",
        "# Monte Carlo Sampling to Find Next Query Point\n",
        "def suggest_next_query(nn_model, input_dim, x_scaler, y_mean, y_std, n_candidates=10000):\n",
        "    \"\"\"\n",
        "    Uses Monte Carlo sampling to suggest the next query point.\n",
        "    \"\"\"\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    nn_model.eval()\n",
        "\n",
        "    # Generate random candidate points uniformly in [0,1]^d\n",
        "    candidates = np.random.rand(n_candidates, input_dim)\n",
        "\n",
        "    #Normalise candidates using fitted scaler\n",
        "    candidates_norm = x_scaler.transform(candidates)\n",
        "\n",
        "    # Predict for normalised candidates\n",
        "    with torch.no_grad():\n",
        "        preds_norm = model(torch.tensor(candidates_norm, dtype=torch.float32).to(device)).cpu().numpy()\n",
        "\n",
        "    # Select candidate with highest predicted value\n",
        "    best_idx = np.argmax(preds_norm)\n",
        "    x_next_norm = candidates_norm[best_idx]\n",
        "    y_pred_norm = preds_norm[best_idx]\n",
        "\n",
        "    # Denormalise back to original scale\n",
        "    x_next = x_scaler.inverse_transform(x_next_norm.reshape(1, -1)).flatten()\n",
        "    y_pred = y_pred_norm * y_std + y_mean\n",
        "\n",
        "    return x_next, y_pred"
      ],
      "metadata": {
        "id": "zqerH2bMFSoJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train a surrogate GP model\n",
        "def train_gp(Xn, yn, kernel=None, n_restarts_optimizer=10, random_state=42):\n",
        "  if kernel is None:\n",
        "    d = Xn.shape[1]\n",
        "    kernel = C(1.0, (1e-3, 1e3)) * Matern(length_scale=np.ones(d),\n",
        "                                          length_scale_bounds=(1e-6, 1e3),\n",
        "                                          nu=2.5)\n",
        "    kernel += WhiteKernel(noise_level=1e-6, noise_level_bounds=(1e-8, 1e1))\n",
        "\n",
        "  gp_model = GaussianProcessRegressor(kernel=kernel,\n",
        "                                      normalize_y=False,\n",
        "                                      n_restarts_optimizer=n_restarts_optimizer,\n",
        "                                      random_state=random_state)\n",
        "  gp_model.fit(Xn, yn)\n",
        "\n",
        "  return gp_model\n",
        "\n",
        "# Use NN to predict the shortlisted batch (returns normalised preds)\n",
        "def nn_predict(nn_model, X_scaled, batch=1024):\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  nn_model.to(device)\n",
        "  nn_model.eval()\n",
        "  nn_preds = []\n",
        "  with torch.no_grad():\n",
        "    for i in range(0, X_scaled.shape[0], batch):\n",
        "      xb = X_scaled[i:i+batch]\n",
        "      xb_t = torch.tensor(xb, dtype=torch.float32).to(device)\n",
        "      preds = nn_model(xb_t).cpu().numpy().reshape(-1)\n",
        "      nn_preds.append(preds)\n",
        "\n",
        "  nn_preds = np.concatenate(nn_preds, axis=0)\n",
        "  return nn_preds\n",
        "\n",
        "# Two stage approach using GP and NN to find Next Query Point\n",
        "def suggest_next_query_two_stage(nn_model, gp_model, input_dim, x_scaler, y_mean, y_std,\n",
        "                                 stage1_size=20000, stage2_size=1000, gp_acq_k=1.96, nn_batch=1024, current_best_x=None, base_radius=0.5):\n",
        "  \"\"\"\n",
        "    Two-stage selection:\n",
        "      1) Sample stage1_size candidates uniformly in [0,1]^d.\n",
        "      2) Scale them and evaluate GP (mu, std) -> acquisition = mu + gp_acq_k * std.\n",
        "      3) Shortlist top `shortlist` candidates by GP acquisition.\n",
        "      4) Re-rank shortlist by NN predicted mean (NN trained on scaled inputs).\n",
        "      5) Return raw chosen x (in [0,1]^d) and denormalised predicted y.\n",
        "\n",
        "    Returns:\n",
        "      x_next_raw: (d,) raw candidate in [0,1]\n",
        "      y_pred_raw: float predicted output in original scale\n",
        "  \"\"\"\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "  # Generate random candidate points uniformly in [0,1]^d\n",
        "  #candidates = np.random.rand(stage1_size, input_dim)\n",
        "\n",
        "  # Generate random canditates based on dimension importance\n",
        "  gp_imp = get_gp_importance(gp_model)\n",
        "  nn_imp = get_nn_importance(nn_model, Xn)\n",
        "  importance = combine_importance(gp_imp, nn_imp)\n",
        "  #candidates = sample_candidates_weighted(importance, n_samples=stage1_size)  # during exploration\n",
        "  candidates = sample_candidates_weighted_local(importance, n_samples=stage1_size, center=current_best_x, base_radius=base_radius)  # during exploitation\n",
        "\n",
        "\n",
        "  #Normalise candidates using fitted scaler\n",
        "  candidates_norm = x_scaler.transform(candidates)\n",
        "\n",
        "  # GP predict on scaled candidates (returns normalized outputs)\n",
        "  mu_gp, sigma_gp = gp_model.predict(candidates_norm, return_std=True)     # both shape (stage1_size,)\n",
        "  # Acquisition: simple UCB-like\n",
        "  gp_acq = mu_gp + gp_acq_k * sigma_gp\n",
        "\n",
        "  # Shortlist top-k candidates by GP acquisition\n",
        "  top_idx = np.argsort(gp_acq)[-stage2_size:]\n",
        "  X_short_raw = candidates[top_idx]         # raw coordinates (shortlist)\n",
        "  X_short_scaled = candidates_norm[top_idx]   # scaled coordinates for NN\n",
        "\n",
        "  nn_preds_norm = nn_predict(nn_model, X_short_scaled, batch=nn_batch)\n",
        "  # nn_preds_norm are in normalized y-space (because NN trained on yn).\n",
        "  # We'll rank by normalized preds (same order as raw).\n",
        "  best_local = np.argmax(nn_preds_norm)\n",
        "  x_next = X_short_raw[best_local]            # keep in [0,1] space\n",
        "\n",
        "  # The NN predicted normalized y so we denormalize it\n",
        "  y_pred_norm = nn_preds_norm[best_local]\n",
        "  y_pred = float(y_pred_norm * y_std + y_mean)\n",
        "\n",
        "  return x_next, y_pred\n",
        "\n"
      ],
      "metadata": {
        "id": "7YMjp2qQiGQ2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Approach to down-weight low importance dimensions\n",
        "# Get nn importance\n",
        "def get_nn_importance(nn_model, X_scaled):\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  nn_model.to(device)\n",
        "  nn_model.eval()\n",
        "  X_t = torch.tensor(X_scaled, dtype=torch.float32, requires_grad=True)\n",
        "  preds = nn_model(X_t).sum()\n",
        "  preds.backward()\n",
        "  grads = X_t.grad.abs().mean(dim=0).numpy()\n",
        "  return grads / grads.sum()\n",
        "\n",
        "# Get gp importance\n",
        "def get_gp_importance(gp_model):\n",
        "  ls = np.array(gp_model.kernel_.k1.k2.length_scale).flatten()\n",
        "  raw = 1.0 / (ls + 1e-8)\n",
        "  return raw / raw.sum()\n",
        "\n",
        "# Commbine nn_importance and gp_importance\n",
        "def combine_importance(gp_imp, nn_imp, gp_weight=0.6):\n",
        "  imp = gp_weight * gp_imp + (1 - gp_weight) * nn_imp\n",
        "  return imp / imp.sum()\n",
        "\n",
        "# Generate candidates based on combined importance\n",
        "def sample_candidates_weighted(importance, n_samples=10000):\n",
        "    \"\"\"\n",
        "    Generate candidate samples where each dimension is sampled\n",
        "    more narrowly if its importance is low.\n",
        "\n",
        "    importance: array of shape [d] summing to 1\n",
        "    \"\"\"\n",
        "    dim = len(importance)\n",
        "\n",
        "    # Scale ranges: important dims sampled wide, weak dims sampled tight.\n",
        "    # Values stay within [0,1].\n",
        "    #\n",
        "    # scale = 1.0 => explore full [0,1]\n",
        "    # scale = 0.2 => explore only central 20%\n",
        "    #\n",
        "    scale = 0.1 + 0.9 * importance  # ensures minimum variety\n",
        "\n",
        "    # Sample raw uniform values\n",
        "    raw = np.random.rand(n_samples, dim)\n",
        "\n",
        "    # Apply scaling around 0.5 (centralised exploration in weak dims)\n",
        "    candidates = 0.5 + (raw - 0.5) * scale\n",
        "\n",
        "    # Clip to ensure valid bounds\n",
        "    candidates = np.clip(candidates, 0.0, 1.0)\n",
        "\n",
        "    return candidates\n",
        "\n",
        "# Generate candidates for exploitation based on combined importance\n",
        "def sample_candidates_weighted_local(importance, n_samples,  center, base_radius=0.1):\n",
        "    \"\"\"\n",
        "    Importance-weighted local sampling around a known good point.\n",
        "\n",
        "    importance : (d,) importance weights, sum to 1\n",
        "    center     : (d,) current_best_x in [0,1]\n",
        "    base_radius: max local radius for most important dimensions\n",
        "    \"\"\"\n",
        "    dim = len(importance)\n",
        "\n",
        "    # More important dims get larger local radius\n",
        "    radius = base_radius * (0.1 + 0.9 * importance)\n",
        "\n",
        "    noise = (np.random.rand(n_samples, dim) - 0.5) * 2.0\n",
        "    candidates = center + noise * radius\n",
        "\n",
        "    # Clip to ensure valid bounds\n",
        "    candidates = np.clip(candidates, 0.0, 1.0)\n",
        "\n",
        "    return candidates"
      ],
      "metadata": {
        "id": "P_v3EaHYIOsw"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Decide function and batch_size\n",
        "func = '8'       # number between 1 and 9 representing BBO function\n",
        "batch_size = 8   # number or None\n",
        "\n",
        "# Load data and normalise\n",
        "X, y = load_initial_files(function=func)\n",
        "X, y = append_new_data(X, y, function=func)\n",
        "current_best_x = X[np.argmax(y)]  # observed best only\n",
        "Xn, yn, y_mean, y_std, x_scaler = normalise_data(X, y)\n",
        "\n",
        "print(len(Xn))\n",
        "print(max(y))\n",
        "print(max(yn))\n",
        "\n",
        "# Calcualte input shape\n",
        "input_dim = Xn.shape[1]\n",
        "\n",
        "# Train NN model\n",
        "nn_model = train_nn(Xn, yn, input_dim, lr=0.01, epochs=500, batch_size=batch_size)\n",
        "\n",
        "# Train GP model\n",
        "gp_model = train_gp(Xn, yn, kernel=None, n_restarts_optimizer=10, random_state=42)\n",
        "\n",
        "# Get the Next Query Point\n",
        "#x_next, y_pred = suggest_next_query(model, input_dim, x_scaler, y_mean, y_std, n_candidates=50000)\n",
        "# gp_acq_k changed to 0.3 from 1.96 at the start of exploitation\n",
        "\n",
        "x_next, y_pred = suggest_next_query_two_stage(nn_model, gp_model, input_dim, x_scaler, y_mean, y_std,\n",
        "  stage1_size=10000, stage2_size=800, gp_acq_k=0.2, nn_batch=512, current_best_x=current_best_x, base_radius=0.12\n",
        ")\n",
        "\n",
        "print(\"\\nFunction:\", func)\n",
        "print(\"\\nSuggested next input (x_next):\", '-'.join(map(str, np.round(x_next, 6))))\n",
        "#print(\"\\nPredicted output estimate:\", float(y_pred[0]))\n",
        "print(\"\\nPredicted output estimate:\", float(y_pred))\n"
      ],
      "metadata": {
        "id": "sY5CPq-z8xvC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7188f41a-a1dc-4c1d-c34e-660d5ccd816f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50\n",
            "9.9450768395815\n",
            "1.572567695294003\n",
            "\n",
            "Function: 8\n",
            "\n",
            "Suggested next input (x_next): 0.090796-0.13846-0.178644-0.020794-0.996394-0.533622-0.231853-0.939059\n",
            "\n",
            "Predicted output estimate: 9.652754108607597\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/gaussian_process/kernels.py:452: ConvergenceWarning: The optimal value found for dimension 5 of parameter k1__k2__length_scale is close to the specified upper bound 1000.0. Increasing the bound and calling fit again may find a better value.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Week 11\n",
        "\n",
        "Function: 1\n",
        "\n",
        "Suggested next input (x_next): 0.328055-0.568992\n",
        "\n",
        "Predicted output estimate: -1.5010868780465246e-05\n",
        "\n",
        "Function: 2\n",
        "\n",
        "Suggested next input (x_next): 0.690308-0.961842\n",
        "\n",
        "Predicted output estimate: 0.625917696589368\n",
        "\n",
        "Function: 3\n",
        "\n",
        "Suggested next input (x_next): 0.510739-0.497528-0.443501\n",
        "\n",
        "Predicted output estimate: -0.021569856598383508\n",
        "\n",
        "Function: 4\n",
        "\n",
        "Suggested next input (x_next): 0.390192-0.428036-0.33289-0.405141\n",
        "\n",
        "Predicted output estimate: -0.7662211030218735\n",
        "\n",
        "Function: 5\n",
        "\n",
        "Suggested next input (x_next): 0.16303-1.0-1.0-1.0\n",
        "\n",
        "Predicted output estimate: 4242.028572332445\n",
        "\n",
        "Function: 6\n",
        "\n",
        "Suggested next input (x_next): 0.463007-0.321444-0.537318-0.70508-0.0\n",
        "\n",
        "Predicted output estimate: -0.2165142492871298\n",
        "\n",
        "Function: 7\n",
        "\n",
        "Suggested next input (x_next): 0.0-0.244433-0.41669-0.288534-0.326959-0.680382\n",
        "\n",
        "Predicted output estimate: 2.296553357429581\n",
        "\n",
        "Function: 8\n",
        "\n",
        "Suggested next input (x_next): 0.090796-0.13846-0.178644-0.020794-0.996394-0.533622-0.231853-0.939059\n",
        "\n",
        "Predicted output estimate: 9.652754108607597"
      ],
      "metadata": {
        "id": "azfR6I4b46VX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Week 10\n",
        "\n",
        "Function: 1\n",
        "\n",
        "Suggested next input (x_next): 0.329036-0.431477\n",
        "\n",
        "Predicted output estimate: -2.6398105065961967e-05\n",
        "\n",
        "Function: 2\n",
        "\n",
        "Suggested next input (x_next): 0.684762-0.956283\n",
        "\n",
        "Predicted output estimate: 0.5979956515253373\n",
        "\n",
        "Function: 3\n",
        "\n",
        "Suggested next input (x_next): 0.541094-0.476141-0.429833\n",
        "\n",
        "Predicted output estimate: -0.014016835391371288\n",
        "\n",
        "Function: 4\n",
        "\n",
        "Suggested next input (x_next): 0.379054-0.415621-0.376105-0.4053\n",
        "\n",
        "Predicted output estimate: -1.3280666630432822\n",
        "\n",
        "Function: 5\n",
        "\n",
        "Suggested next input (x_next): 0.161038-1.0-1.0-1.0\n",
        "\n",
        "Predicted output estimate: 4234.224157433494\n",
        "\n",
        "Function: 6\n",
        "\n",
        "Suggested next input (x_next): 0.485318-0.35441-0.532001-0.735756-0.002593\n",
        "\n",
        "Predicted output estimate: -0.5047795229646672\n",
        "\n",
        "Function: 7\n",
        "\n",
        "Suggested next input (x_next): 0.0-0.246499-0.426534-0.258151-0.365936-0.706056\n",
        "\n",
        "Predicted output estimate: 2.185576374134149\n",
        "\n",
        "Function: 8\n",
        "\n",
        "Suggested next input (x_next): 0.128787-0.124725-0.195336-0.024228-1.0-0.534909-0.22382-0.947785\n",
        "\n",
        "Predicted output estimate: 9.731860346327224\n"
      ],
      "metadata": {
        "id": "Vg7RhUgVAIm-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Week 9\n",
        "\n",
        "Function: 1\n",
        "\n",
        "Suggested next input (x_next): 0.20084-0.740525\n",
        "\n",
        "Predicted output estimate: -2.2611736184759493e-05\n",
        "\n",
        "Function: 2\n",
        "\n",
        "Suggested next input (x_next): 0.697663-0.999431\n",
        "\n",
        "Predicted output estimate: 0.6019257317340984\n",
        "\n",
        "Function: 3\n",
        "\n",
        "Suggested next input (x_next): 0.5116-0.466301-0.440801\n",
        "\n",
        "Predicted output estimate: -0.0073684692582915295\n",
        "\n",
        "Function: 4\n",
        "\n",
        "Suggested next input (x_next): 0.337602-0.314128-0.323601-0.447251\n",
        "\n",
        "Predicted output estimate: 0.2144506112489193\n",
        "\n",
        "Function: 5\n",
        "\n",
        "Suggested next input (x_next): 0.106033-1.0-1.0-1.0\n",
        "\n",
        "Predicted output estimate: 4393.815187907966\n",
        "\n",
        "Function: 6\n",
        "\n",
        "Suggested next input (x_next): 0.463141-0.457153-0.632226-0.697789-0.0\n",
        "\n",
        "Predicted output estimate: -0.36433352926084206\n",
        "\n",
        "Function: 7\n",
        "\n",
        "Suggested next input (x_next): 0.0-0.273026-0.493981-0.248861-0.418811-0.645849\n",
        "\n",
        "Predicted output estimate: 2.3946101918432645\n",
        "\n",
        "Function: 8\n",
        "\n",
        "Suggested next input (x_next): 0.032703-0.075576-0.154423-0.035445-0.99059-0.497687-0.174691-0.986528\n",
        "\n",
        "Predicted output estimate: 9.73540021240301\n"
      ],
      "metadata": {
        "id": "xoMHU_TZmunL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Week 8\n",
        "Function: 1\n",
        "\n",
        "Suggested next input (x_next): 0.354466-0.463725\n",
        "\n",
        "Predicted output estimate: -6.573937079029337e-05\n",
        "\n",
        "Function: 2\n",
        "\n",
        "Suggested next input (x_next): 0.684793-0.736977\n",
        "\n",
        "Predicted output estimate: 0.5478891261102885\n",
        "\n",
        "Function: 3\n",
        "\n",
        "Suggested next input (x_next): 0.671012-0.54088-0.410996\n",
        "\n",
        "Predicted output estimate: -0.07154796838749342\n",
        "\n",
        "Function: 4\n",
        "\n",
        "Suggested next input (x_next): 0.462778-0.459808-0.427924-0.383695\n",
        "\n",
        "Predicted output estimate: 1.4924733828472245\n",
        "\n",
        "Function: 5\n",
        "\n",
        "Suggested next input (x_next): 0.450158-0.310399-0.558612-0.719998\n",
        "\n",
        "Predicted output estimate: 416.6177720858795\n",
        "\n",
        "Function: 6\n",
        "\n",
        "Suggested next input (x_next): 0.352618-0.580837-0.570192-0.621771-0.372965\n",
        "\n",
        "Predicted output estimate: -0.5151560075399452\n",
        "\n",
        "Function: 7\n",
        "\n",
        "Suggested next input (x_next): 0.391166-0.399851-0.48006-0.389445-0.406096-0.616639\n",
        "\n",
        "Predicted output estimate: 1.7499281039217427\n",
        "\n",
        "Function: 8\n",
        "\n",
        "Suggested next input (x_next): 0.416048-0.59922-0.417048-0.424239-0.551884-0.585992-0.386618-0.514817\n",
        "\n",
        "Predicted output estimate: 9.054074978896033\n",
        "\n"
      ],
      "metadata": {
        "id": "fF8gtzSbTE6-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **## Week7**\n",
        "Function: 1\n",
        "\n",
        "Suggested next input (x_next): 0.961902-0.54151\n",
        "\n",
        "Predicted output estimate: 0.0003957174409107497\n",
        "\n",
        "Function: 2\n",
        "\n",
        "Suggested next input (x_next): 0.686326-0.048467\n",
        "\n",
        "Predicted output estimate: 0.5931130065069816\n",
        "\n",
        "Function: 3\n",
        "\n",
        "Suggested next input (x_next): 0.785819-0.951069-0.007398\n",
        "\n",
        "Predicted output estimate: -0.07821291139128447\n",
        "\n",
        "Function: 4\n",
        "\n",
        "Suggested next input (x_next): 0.408168-0.42467-0.350333-0.464759\n",
        "\n",
        "Predicted output estimate: 0.3892309433321408\n",
        "\n",
        "Function: 5\n",
        "\n",
        "Suggested next input (x_next): 0.165658-0.993001-0.985802-0.828885\n",
        "\n",
        "Predicted output estimate: 3679.3006173709423\n",
        "\n",
        "Function: 6\n",
        "\n",
        "Suggested next input (x_next): 0.399356-0.472775-0.272075-0.930991-0.004327\n",
        "\n",
        "Predicted output estimate: -0.33820016205812065\n",
        "\n",
        "Function: 7\n",
        "\n",
        "Suggested next input (x_next): 0.051607-0.242133-0.329607-0.131528-0.404377-0.688463\n",
        "\n",
        "Predicted output estimate: 1.993543925493233\n",
        "\n",
        "Function: 8\n",
        "\n",
        "Suggested next input (x_next): 0.065492-0.074877-0.151838-0.036631-0.882332-0.83748-0.404222-0.901998\n",
        "\n",
        "Predicted output estimate: 9.877420081086175\n"
      ],
      "metadata": {
        "id": "cCDAEDEfM9ei"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **## Week6**\n",
        "\n",
        "Function: 1\n",
        "\n",
        "Suggested next input (x_next): 0.147927-0.999351\n",
        "\n",
        "Predicted output estimate: 0.004738142161169105\n",
        "\n",
        "Function: 2\n",
        "\n",
        "Suggested next input (x_next): 0.576225-0.995582\n",
        "\n",
        "Predicted output estimate: 1.0778257373391364\n",
        "\n",
        "Function: 3\n",
        "\n",
        "Suggested next input (x_next): 0.306294-0.000901-0.737840\n",
        "\n",
        "Predicted output estimate: 0.03597608387388612\n",
        "\n",
        "Function: 4\n",
        "\n",
        "Suggested next input (x_next): 0.362616-0.390935-0.358916-0.408803\n",
        "\n",
        "Predicted output estimate: 0.4543251119036995\n",
        "\n",
        "Function: 5\n",
        "\n",
        "Suggested next input (x_next): 0.379668-0.980190-0.997527-0.939278\n",
        "\n",
        "Predicted output estimate: 4366.357278991082\n",
        "\n",
        "Function: 6\n",
        "\n",
        "Suggested next input (x_next): 0.377302-0.427069-0.554688-0.835249-0.037887\n",
        "\n",
        "Predicted output estimate: -0.23066364279575358\n",
        "\n",
        "Function: 7\n",
        "\n",
        "Suggested next input (x_next): 0.002100-0.111359-0.320991-0.376242-0.229457-0.955090\n",
        "\n",
        "Predicted output estimate: 2.464740596873976\n",
        "\n",
        "Function: 8\n",
        "\n",
        "Suggested next input (x_next): 0.026980-0.613170-0.025877-0.359845-0.896836-0.008212-0.028519-0.131032\n",
        "\n",
        "Predicted output estimate: 10.435474844266569\n",
        "\n"
      ],
      "metadata": {
        "id": "Mn3uM-cp3H4a"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4_Ueln1kSCIt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}